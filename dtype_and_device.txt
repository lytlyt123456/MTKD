model定义好之后，会调用convert_weights()方法，将model中nn.Conv1d, nn.Conv2d, nn.Linear, nn.MultiheadAttention
中的所有nn.Parameter都转化为torch.float16，然后model.cuda()将model中所有nn.Parameter都转到cuda上。

如果model建好后不调用convert_weights()和cuda()，就要在构造方法里调用（但不建议这样做）。

写模型的时候，需要做的是：
1、重定义LayerNorm。
2、forward方法里，在推理计算时，将构造方法中定义的nn.Parameter的dtype向nn.Conv2d等看齐，将外来普通张量的dtype和device
均向nn.Conv2d等看齐，image不用转device。

注意：
1、module = nn.Module(), output = model(input)，得到的输出张量output的dtype和device与module中的参数完全一致。
2、得到logits后，要把logits转化为torch.float32再计算损失函数。